---
layout: post
title: Spatial Pyramid Pooling структура в свёрточной нейронной сети
date: 2017-03-08
category: Computer vision
tags: [CV, CNN, object classification]
use_math: true
---

Любая свёрточная нейронная сеть, применяемая для классификации объектов, структурно легко разделяется на две части. Первая состоит из свёрточных 
(*convolution*) и объединяющих (*pooling*) слоёв (сюда же все нелинейности, LRN, batch normalization и т.п.) и по исходной картинке формирует 
трёхмерную матрицу особенностей (*features*). Вторая часть сети является классификатором, который, взяв набор особенностей, выдаёт класс объекта на 
изображении (вернее вектор sofmax с вероятностями для каждого класса).

Статья [1] предлагает использовать *spatial pyramid pooling* слой между свёрточной частью и классификатором, чтобы иметь возможность классифицировать
изображения произвольных размеров (в разумных пределах).

<!--more-->

Итак обычная свёрточная сеть выглядит следующим образом:

![Структура обычной свёрточной сети]({{ site.baseurl }}/images/2017-03/spp_cnn_simple_structure.svg)

На выходе свёрточной части мы получаем трехмерную матрицу особенностей, первая размерность - это количество каналов, которое мы меняем явно, задавая
этот параметр, когда задаём свёрточную сеть. Вторая и третья - это пространственные размерности, они определяются размерами входного изображения и 
той структурой сверточной части сети, которую мы используем. Полученная трехмерная матрица преобразуется в одномерный вектор (преобразование в данном
случае это просто проход по матрице в растровом порядке и копирование элементов в вектор) и этот вектор подаётся на вход классификатора. Так как 
на вход классификатора должен подаваться вектор фиксированного размера, то и трехмерная матрица должна иметь фиксированные размеры, а так как 
пространственные размеры матрицы особенностей при заданной структуре сети полностью определяются размерами входного изображения, то изображения, 
подаваемые на вход сети могут быть только определенного размера.

> #### Пример.
> 
> В качестве примера рассмотрим *AlexNet*, описанную в статье [2]. Структуру сети можно посмотреть
> [на рисунке]({{ site.baseurl }}/images/2017-03/alexnet.svg).
> Из того, что нас интересует: на вход подается трехканальне изображение размера *227 x 227*, которое пройдя через последовательность свёрточных и 
> объединяющих слоёв приходит на вход классификатора в виде трехмерной матрицы особенностей *256 x 6 x 6* или, что тоже самое, в виде вектора с 
> *256 * 6 * 6 = 9216* компонентами. Допустим мы попытаемся подать на вход сети изображение с размерами отличными от заявленных, например, 
> *259 x 227*, тогда после применения свёрточных и объединяющих слоёв на вход классификатора придёт трехмерная матрица особенностей *256 x 7 x 6*, 
> или вектор размерности *256 * 7 * 6 = 10752* и классификатор не отработает.
>

Таким образом, чтобы классифицировать объект на некотором изображении с использованием свёрточной нейронной сети необходимо преобразовать изображение 
к тому размеру, который сеть принимает на вход. Примеры таких преобразований схематично изображены на следующем рисунке:

![Преобразование изображения для свёрточной сети]({{ site.baseurl }}/images/2017-03/img_distort_for_cnn.svg)

Видно, что такого рода преобразования, либо добавляют искажения в исходное изображение, либо могут обрезать часть объекта, который мы хотим 
классифицировать. Естественно это негативно сказывается на качестве классификации.

Чтобы не приводить изображение к определенному размеру и не вносить искажений, в статье [1] предлагается заменить последний перед классификатором 
объединяющий слой на *spatial pyramid pooling* слой. Т.е. структура сети изменится следующим образом:

![Структура SPP свёрточной сети]({{ site.baseurl }}/images/2017-03/spp_cnn_structure_with_spp.svg)

*Spatial pyramid pooling* слой, как ясно из названия, это "пирамида" из обобщающих слоёв, поэтому прежде чем двигаться дальше разберёмся как
работается обобщающий слой. Итак, в классической ситуации для обобщающего слоя мы задаем:

1. Размер окна $(W_{win}, H_{win})$

2. Размер сдвига по горизонтали и вертикали $(W_{str}, H_{str})$. 

3. Ширину бордюра добавляемого вокруг входной матрицы $(W_{pad}, H_{pad})$. 

4. Обобщающую функцию (в основном используется максимум).

Тогда, подавая на вход такого слоя матрицу особенностей размера $(W_{inp}, H_{inp})$ на выходе мы получим матрицу с размерами:

$$(W_{out}, H_{out}) = ( (W_{inp} - W_{win} + 2 \cdot W_{pad}) / W_{str} + 1, (H_{inp} - H_{win} + 2 \cdot H_{pad}) / W_{str} + 1)$$

Каждый элемент выходной матрицы, равен значению обобщающей функции, вычисленному на соотвествующем прямоугольном окне размера $(W_{win}, H_{win})$
входной матрицы. 
 
Возвращаясь к нашей задаче, вместо того, чтобы задавать размеры окна и сдвиг, зафиксируем размеры выходной матрицы. А размер окна и размер сдвига 
будем вычислять исходя из размеров входной матрицы:

$$(W_{win}, H_{win}) = (\left \lceil{W_{out} / W_{inp}}\right \rceil, \left \lceil{H_{out} / H_{inp}}\right \rceil)$$

$$(W_{str}, H_{str}) = (\left \lfloor{W_{out} / W_{inp}}\right \rfloor, \left \lfloor{H_{out} / H_{inp}}\right \rfloor)$$

Фактически мы хотим разбить входную матрицу на определенное количество ячеек, вычислить обобщающую функцию на каждой ячейке, и поместить результат
в выходную матрицу. Поскольку теперь независимо от размера входного изображения на выходе такого обобщающего слоя будет трехмерная матрица всегда
одних и тех же размеров, то и вектор, который мы подадим в классификатор, не будет меняться при изменении размеров изображения.

Чтобы улучшить качество классификации, вместо одного такого слоя в статье предлагается использовать пирамиду слоёв. Т.е. вместо одной матрицы на
выходе будем иметь несколько, которые развернём в несколько векторов, которые объединим и подадим на вход классификатора. Авторы статьи предлагают 
использовать пирамиду из четырех слоёв с размерами (на выходе) *[6 x 6, 3 x 3, 2 x 2, 1 x 1]*. 

> #### Пример
> 
> Возвращаясь вновь к *AlexNet*, заменим слой *MaxPool5* на *spatial pyramid pooling* слой получим на выходе слоя вектор размерности:
>
> *256 * 6 * 6 + 256 * 3 * 3 + 256 * 2 * 2 + 256 * 1 * 1 = 256 * 50 = 12 800*
>

Заметим, что верхний слой пирамиды с ячейкой *1 x 1* фактически выдаёт "глобальное" обобщение подсчитывая максимум по каждому из каналов особенностей.

Итак, на вход сети с *spatial pyramid pooling* мы можем подавать изображение любого размера, без необходимости реаспектации и даже одно и тоже 
изображение в разных масштабах.

### Тренировка

Теоретически новую сеть можно тренировать на изображениях произвольных размеров с использованием обычного подхода с обратным распространением ошибки.
Однако, на практике это не удобно, поскольку все фреймворки оптимизированы на использование GPU и требуют подавать на вход четырехмерные матрицы
(размер пачки - количество каналов - высота - ширина) фиксированного размера. Поэтому в статье [1] авторы предлагают тренировать стандартно, приводя
тренировочные изображения к фиксированному размеру. При этом чередуя размер изображений от эпохи к эпохе. Авторы при тренировке используют два размера
тренируя первую эпоху на изображениях *224 x 224*, вторую на изображениях *180 х 180*, третью опять *224 х 224* и т.д.

Авторы приводят данные, что замена обобщающего слоя в известных сетях (ZF-5, ConvNet, OverFeat) приводит к уменьшению *top-1* ошибки на 0.5% - 1.65%
при тренировке на изображениях только одного размера, и на 1.4%-2.4% при тренировки чередуя изображения двух размеров от эпохи к эпохе. Причем
тренировка с чередованием размера изображения, всегда даёт уменьшение ошибки, по сравнению с тренировкой на изображениях одного размера.

Естественно не смотря на такой подход к тренировке, классификация проводится на изображениях произвольного размера.

### Вывод

Авторы статьи предложили подход позволяющий улучшить качество классификации, и использовать свёрточную сеть для классификации объектов на изображениях
произвольных размеров, без необходимости предварительных преобразований этих изображений перед подачей их на вход сети.

---
 
### Литература

1. *K. He, X. Zhang, S. Ren, J. Sun, "Spatial pyramid pooling in deep convolutional networks for visual recognition," 
[arXiv:1406.4729](https://arxiv.org/abs/1406.4729) 2014*

2. *A. Krizhevsky, I. Sutskever, and G. Hinton, “Imagenet classification with deep convolutional neural networks,” in NIPS, 2012.*

3. *K. Grauman and T. Darrell, “The pyramid match kernel: Discriminative classiﬁcation with sets of image features,” in ICCV, 2005.*

